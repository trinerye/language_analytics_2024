{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns the data in to a list + sorts it\n",
    "dirs = sorted(os.listdir(\"data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints the subfolders in data \n",
    "dirs\n",
    "dirs_test = [dirs[0]]\n",
    "filenames_test = [\"0102.a1.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "344\n",
      "292\n",
      "185\n",
      "114\n",
      "80\n",
      "57\n",
      "35\n",
      "29\n",
      "21\n",
      "12\n",
      "15\n",
      "3\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# for every subfolder\n",
    "for directory in dirs:\n",
    "\n",
    "    # get the individual filenames\n",
    "    filenames = sorted(os.listdir(os.path.join(\"data\", directory)))\n",
    "\n",
    "    print(len(filenames))\n",
    "\n",
    "    columns = [\"NOUN\", \"VERB\", \"ADJ\", \"ADV\", \"PERSON\", \"LOC\", \"ORG\"]\n",
    "\n",
    "    final_results = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # for each individual file\n",
    "    for text_file in filenames:\n",
    "        filepath = os.path.join(\"data\", directory, text_file)\n",
    "       \n",
    "        with open(filepath, encoding='latin1') as file:\n",
    "            text = file.read()\n",
    "            # print(text)\n",
    "            text_cleaned = re.sub(r'\\<[^>]*\\>', \"\", text)\n",
    "        \n",
    "            # print(text_cleaned)\n",
    "\n",
    "        doc = nlp(text_cleaned)\n",
    "    \n",
    "        person = set()\n",
    "        loc = set()\n",
    "        org = set()\n",
    "        \n",
    "        for word in doc.ents:\n",
    "\n",
    "            if word.label_ == \"PERSON\":\n",
    "                person.add(str(word))\n",
    "\n",
    "            elif word.label_ == \"LOC\":\n",
    "                loc.add(str(word))\n",
    "            \n",
    "            elif word.label_ == \"ORG\":\n",
    "                org.add(str(word))\n",
    "\n",
    "\n",
    "       \n",
    "        annotations = []\n",
    "        for token in doc: \n",
    "            annotations.append([token.text, token.pos_])\n",
    "\n",
    "        df = pd.DataFrame(annotations, columns=[\"text\", \"pos\"])\n",
    "\n",
    "        text_pos = df.groupby(\"pos\").count()\n",
    "        # print(text_pos)\n",
    "\n",
    "        df2 = df[df['pos'].isin([\"NOUN\", \"VERB\", \"ADJ\", \"ADV\"])] \n",
    "\n",
    "        text_pos = df2.groupby(\"pos\").count()\n",
    "        \n",
    "        total_words = df[-df['pos'].isin([\"SPACE\", \"SYM\", \"PUNCT\", \"NUM\"])] \n",
    "\n",
    "        total_words = len(total_words)/10000\n",
    "\n",
    "        # print(text_pos)      \n",
    "       \n",
    "        noun = round(text_pos[\"text\"][\"NOUN\"]/total_words)\n",
    "        verb = round(text_pos[\"text\"][\"VERB\"]/total_words)\n",
    "        adj = round(text_pos[\"text\"][\"ADJ\"]/total_words)\n",
    "        adv = round(text_pos[\"text\"][\"ADV\"]/total_words)\n",
    "        person = len(person)\n",
    "        loc = len(loc)\n",
    "        org = len(org)\n",
    "\n",
    "\n",
    "        results = [noun, verb, adj, adv, person, loc, org]\n",
    "\n",
    "\n",
    "        df_results = pd.DataFrame([results], columns=columns)\n",
    "\n",
    "        final_results = pd.concat([final_results, df_results])\n",
    "\n",
    "    # print(final_results)\n",
    "\n",
    "    final_results.to_csv(f\"out/{directory}.results.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
